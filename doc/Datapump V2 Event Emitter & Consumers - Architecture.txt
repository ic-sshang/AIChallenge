Title
Datapump V2 Event Emitter & Consumers - Architecture
Author
Vivek Regonda & Pradeep Sommula
Reviewer
<Add Names Here>
 
Table of Content 
toc
1
6
false
none
list
true
:package:
1f4e6
ðŸ“¦
#EAE6FF
Code Repositories
DatapumpEventEmitter
 (Scanner, Publisher pipeline)
DatapumpPaymentsConsumer
, 
DatapumpPaperlessConsumer
 (downstream services)
1) Executive summary
Modernize the Datapump (DP) process by moving from controller-driven, per-biller executables to a 
containerized, event-driven pipeline
 on Kubernetes. The 
Event Emitter
 (Scanner + Publisher) discovers eligible DP records across all biller shard databases, validates/enriches them, and publishes lightweight messages to an 
Azure Service Bus Topic
. Consumers (Payments/Paperless) authenticate, fetch the payment records and Prepares request payload, call the biller API, and reconcile DP tables.
Features offered by this Solution
Areas
Current Challenges
How itâ€™s Solved
1
Architecture 
The system follows a 
Requestâ€“Response model
, resulting in a 
tightly coupled architecture
.
This limits flexibility, reusability, and scalability as services are directly dependent on each other.
Very Big Monolith application which is challenging to scale and maintain.
Depends on Legacy Skybot Scheduler to invoke datapump controller.
Using legacy .Net 4.8 framework with VB.Net. 
Transition to an 
Event-Driven Architecture (EDA) + Requestâ€“Response
 
model  
to enable 
loosely coupled systems and processes
.
Publishers and subscribers communicate asynchronously through events, improving 
scalability, extensibility, and fault tolerance
.
This decoupling provides the ability to 
add new consumers with minimal impact
, supporting long-term agility.
Transition to Microservices architecture(Publisher & Subscriber Model) having shared repos as Nuget Packages.
Moving towards KEDA autoscaling for scaling Fetcher and Consumer based on count of entities. 
Moving towards LTS dotnet 8 with C#.
2
Retries
Hardcoded retry logic
Not implemented for all the billers
Implementation requires release/deployment
Generic Retry Logic/available and configurable as a feature. 
Exponential backoff: Example exponential wait time 1 sec > 3 sec > 5 sec > 7 sec etc. 
3
Message persistence
NA
Ensuring messages are not lost even if there is a system failure. 
Achieving this by re-processing Dead Letter Queue messages in Azure Service Bus.
4
Scalability 
The current solution has scalability challenges which results delay in data sync with Biller and CIS System.
This solution implements an event-driven architecture for processing datapump records at scale.
It is designed to 
containerized, hosted in Kubernetes
, and supports 
event-driven autoscaling
 using 
KEDA
 and 
Azure Service Bus
.
5
Data Stream Management & Prioritization
The current single-channel approach results in 
no segregation of data streams
, which eliminates the ability to assign 
priority handling across different data types
.
The system 
lacks data-typeâ€“level monitoring
 of posting traffic from InvoiceCloud to Biller/CIS systems, making it difficult to achieve effective 
fault isolation and root-cause analysis
.
Prioritized, Segregated Data Streams
Introduce 
perâ€“data-type queues
 (or topic with 
perâ€“data-type subscriptions
) to enforce 
true stream segregation
.
Use 
message metadata (properties/labels)
 and 
separate processing tiers
 to enable 
priority handling
 (e.g., higher-priority queues with larger consumer pools, higher concurrency, or preferred scaling rules).
Apply 
queue-level throttling and backoff
 so lower-priority traffic cannot starve critical workloads.
Data-Typeâ€“Level Monitoring & Fault Isolation
Enable 
per-queue metrics
 (ingress/egress, active/dead-letter counts, latency) to monitor posting traffic 
by data type
.
Configure 
dead-letter queues (DLQ)
 per stream for 
isolation and targeted remediation
 without impacting other data types.
Emit 
structured logs/diagnostics
 with correlation IDs to 
trace end-to-end
 from InvoiceCloud to Biller/CIS.
Integrate with 
Azure Monitor / Application Insights
 for dashboards, SLOs, and 
alerting
 (e.g., DLQ rate, queue depth, processing lag) at the 
data-type level
.
6
Maintainability
Hard-coded biller configuration in biller class which is not easy to maintain.
Centralized configurable JSON per biller having all static values of billers at one place which makes changing and onboarding a biller easy.
eg: [
  {
    "BillerID": 139,
    "NameTemplate": "{DBA} [Sapiens Coresuite]",
    "Vendor": "SapiensCore",
    "IntegrationClass": "DataPump.Integrations.Software.SapiensCoresuite.SapiensCoresuiteIntegration",
    "Mode": "Standard",
    "Actions": [ "Payment", "Paperless", "AutoPay", "ACHRejects" ],
    "Constraints": {
      "AllowedInvoiceTypes": null,
      "SkipNOCs": true
    }
  }
]
 
Go to Top
2) High-level Architecture
2
0
1
0
4602822661
4674715989
Untitled Diagram-1756076580097.drawio
1
5
11
https://invoicecloud.atlassian.net/wiki
Untitled Diagram-1756076580097.drawio
0
2174
1006.45
3) Repositories & services
Repo
Service/Stage
Tech
Notes
DatapumpEventEmitter
Stage 1 â€” Scanner
.NET 8 worker, containerized, K8s Deployment
Parallel shard query across all biller shard DBs; every x seconds; records candidate billers/keys to fetch.
Divides batch into chunks if the batch size is greater than the max chunk size configured.ivides batch into chunks if the batch size is greater than the max chunk size configured.ivides batch into chunks if the batch size is greater than the max chunk size configured.ivides batch into chunks if the batch size is greater than the max chunk size configured.ivides batch into chunks if the batch size is greater than the max chunk size configured.ivides batch into chunks if the batch size is greater than the max chunk size configured.ivides batch into chunks if the batch size is greater than the max chunk size configured.ivides batch into chunks if the batch size is greater than the max chunk size configured.ivides batch into chunks if the batch size is greater than the max chunk size configured.ivides batch into chunks if the batch size is greater than the max chunk size configured.ivides batch into chunks if the batch size is greater than the max chunk size configured.
Stage 2 â€” Fetcher
.NET 8 worker, containerized
Pulls specific DP rows for the billers marked by Scanner per chunk;
Scales based on no of chunks.
performs the following sub-stages:
2.1 dbValidation
Datapump.DAL + DP.BAL
Validate customer/payment, biller config; enrich message with user/config.
2.2 Prepare Request
DP.BAL
Build request payload/headers for publisher; add to message context.
2.3 Publisher
DP.Common
Publishes 1 message per Datapump row to 
Service Bus
 Payments and Paperless Topics and Updates Outbox table status
DatapumpPaymentsConsumer
Consumer
.NET 8 worker
Fetches â€œPayments Topicâ€ records
Build Payload Request and Validations
Stages: 
auth
 â†’ 
callApi
 â†’ reconcile DP tables.
DatapumpPaperlessConsumer
Consumer
.NET 8 worker
Fetches â€œPaperless Topicâ€ records
Same stages, different topic.
Note
: For Message Contracts both publisher and consumer will use shared biller code base as a Nuget package.
 
Go to Top
4) Message flow (detailed)
wide
1800
  participant Scanner
  participant Fetcher
  participant SB as ASB Outbox Topic
  participant DB as Biller Shard DB(s)
  participant SB as ASB Topic
  participant Pay as Payments Consumer
  participant Pap as Paperless Consumer
  Scanner->>DB: Multi-shard query (poll every 5s)
  DB-->>Scanner: Candidate DP rows (ids/billerIds)
  Scanner->> Inserts outbox record and service bus message per batch 
  Scanner->>Fetcher: Marked work items (queue/in-mem/cache)
  Fetcher->>DB: Fetch DP rows for marked billers per batch
  Fetcher->>Fetcher: 2.1 dbValidation (DAL/BAL)
  Fetcher->>Fetcher: 2.3 Publisher (DP.Common)
  Fetcher->>SB: Publish message {dpId,billerId,...}
  SB-->>Pay: Deliver (subscription=payments)
  SB-->>Pap: Deliver (subscription=paperless)
  Pay->>Auth: Stage Query Payment Records and Prepare Request (Biller.BAL)
  Pay->>Auth: Stage auth (Biller.BAL)
  Pap->>Auth: Stage auth (Biller.BAL)
  Pay->>BillerAPI: Final API call (Biller.BAL)
  Pap->>BillerAPI: Final API call (Biller.BAL)
  Pay->>DB: Update DP & DpDetail; log result
  Pap->>DB: Update DP & DpDetail; log result

 
Go to Top
5) Stages & responsibilities
5.1 Scanner (Stage 1)
Responsibility:
 Lightweight, continuous scan across all shard DBs to identify presence of DP work; sleeps 
x seconds
 between scans.
Input:
 None (time-driven).
Output:
 Scans all biller shards to identify eligible DataPump records for processing, and writes them into the 
Outbox table
 in batches with an assigned status.
For each chuuuuuuunknknknknknknk, 
publishes a Service Bus message using  using  using  using  using  using  using 
 containing the 
BillerId
 and the 
range of DataPump record IDs
 included in that batch.
5.2 Fetcher (Stage 2)
Connects to service bus and establishes a biller shard connection per message and batch
Fan-out to shards flagged by Scanner per message; process per DP row.
dbValidation (Datapump.DAL + DP.BAL):
 customer/payment existence; biller settings; enrich context (user/config).
prepareRequest (DP.BAL):
 build request headers/body for downstream publisher/consumer.
Publisher (DP.Common):
 publish to Service Bus Topic with 
correlation
 and 
idempotency
 keys.
Connects to service bus and establishes a biller shard connection per message and batch
Fan-out to shards flagged by Scanner per message; process per DP row.
dbValidation (Datapump.DAL + DP.BAL):
 customer/payment existence; biller settings; enrich context (user/config).
prepareRequest (DP.BAL):
 build request headers/body for downstream publisher/consumer.
Publisher (DP.Common):
 publish to Service Bus Topic with 
correlation
 and 
idempotency
 keys.
KEDA Auto Scaling:
Fetcher 
Application Pod connects to this 
Datapump Outbox Topic 
of Azure Service Bus and 
KEDA scales 
based on message count across the topic.
5.3 Consumers (Payments/Paperless)
Prepare Request
: Query Payment Records, Validate and Prepare Request
auth:
 Get an access token from centralized auth via 
Biller.BAL
 and attach to message context.
callApi:
 Transform biller data issue final API call; log; mark complete; update 
dp
 and 
DpDetail
 rows.
KEDA Auto Scaling:
Consumer 
pods scales based on Azure Service Bus Topic Subscription Count and 
KEDA 
Auto-scales consumers based on subscription type.
 
Go to Top
6) Contracts
6.1 Topic & subscriptions
Contracts 
: 
ScannerToFetcherMessage 
and 
FetcherToConsumerMessage
Topic:
 
datapump-events
 (partitioned, duplicate detection enabled).
Subscriptions:
payments
 (DatapumpPaymentsConsumer)
paperless
 (DatapumpPaperlessConsumer)
6.2
 
Message Published By Scanner (ASB) - Contract
wide
1800
{
  "billerId": "<bigint>",
  "dpStart": "x",
  "dpEnd": "x+50",
  "messageId": "billerId:dpStart+dpEnd"
}

6.3 Message Published By Publisher (ASB) â€” envelope
wide
1800
{
  "dpId": "<guid|bigint>",
  "billerId": "12",
  "eventType": "Payments|Paperless|...",
  "occurredAt": "2025-08-24T00:00:00Z",
  "version": 1,
  "traceId": "billerId:dpId",
  "messageId": "billerId:dpId",
  "source": { "shard": "Shard-12", "table": "dbo.datapump" }
}

Broker attributes
MessageId = billerId:dpId
 (dedupe)
CorrelationId = billerId
 (tracing)
ApplicationProperties
: 
eventType
, 
tenant
, 
billerId
SessionId
 
(optional)
 = 
billerId
 if strict ordering per biller is required.
 
Go to Top
7) Libraries & responsibilities
Datapump.Auth
 (NuGet): Shared library provides abstract for centralized authentication service for the billers. 
Datapmp.Biller.BAL
 (NuGet): biller auth, billerâ†’domain DTO mapping, API invocations; may reuse DP.Common.
Datapump.Redis
 (NuGet): simple get/set wrappers for distributed caching.
Datapump.Common
 (NuGet): helpers (logging, correlation, retry, SB producer, SB Consumer JSON, clock, diagnostics).
Datapump.DAL
 (shared, not NuGet): DB access; 
Publisher may use Shared DAL with EF Core and ADO.NET
, 
Consumer may use internal DAL with ADO.NET
 as per requirement.
8) Deployment & scaling
8.1 Kubernetes
Scanner
 and 
Fetcher
 are separate Deployments (continuous workers). Scanner uses 5s sleep; Fetcher fans out with bounded concurrency.
Consumers
 (Payments/Paperless) as separate Deployments.
8.2 Autoscaling (KEDA)
Consumers:
 scale on 
Service Bus topic subscription backlog
 (0â†’N).
Emitter (Fetcher):
 scale on 
KEDA MSSQL Query Count
 (0â†’N).
8.3 Concurrency knobs (Fetcher)
maxConcurrentBillers
: how many shards processed in parallel.
maxBatchSize
: DP rows per read.
sleepBetweenScans
: 5s (Scanner), adaptive for Fetcher.
 
Go to Top
9) Reliability & idempotency
At-least-once
 delivery via publisher retries + Service Bus.
Duplicate detection
: broker 
MessageId = billerId:dpId
.
DLQ handling
: configure max delivery count; add DLQ replayer or manual tooling.
10) Data validation & enrichment (2.1)
Validate 
customer
, 
payment
, 
biller config
 via Datapump.DAL and DP.BAL.
Enrich with user info and biller settings required to build final request.
If invalid â†’ log and 
do not publish
; optionally write to a validation error queue for analysis.
11) Observability
Structured logs
 with 
traceId
, 
dpId
, 
billerId
, 
stage
.
Metrics(For Future Implementation)
Scanner: shards scanned/sec; candidate count.
Fetcher: DP rows fetched/sec; validation failures; latency; publish latency.
Broker: topic/subscription backlog, ingress/egress rate, DLQ count.
Consumers: API success rate, p95 latency, retry counts.
Distributed tracing
 (OpenTelemetry): span per stage; propagate 
traceId
 via SB.
 
Go to Top
12) Security & secrets
Managed Identity
 for SB, and databases.
Secrets in 
Azure Key Vault
; connection indirection (Shard registry â†’ Key name).
Least privilege
 RBAC on topic/subscription and storage container.
13) Configuration (examples)
Key
Service
Example
Scanner:SleepSeconds
Scanner
5
Fetcher:MaxConcurrentBillers
Fetcher
12
Fetcher:BatchSize
Fetcher
1000
ServiceBus:TopicName
Publisher/Consumers
dp-events
ServiceBus:Subscriptions
Consumers
payments
, 
paperless
Auth:Authority
Consumers
https://auth.example.com
 
Go to Top
14) Failure handling & runbooks
Publish failures
: retry with exponential backoff; rely on SB dedupe; alert on repeated failures.
Consumer failures
: automatic retries; on DLQ, run re-drive procedure with reason analysis in the future.
 URL:/spaces/ED/pages/4602822661/Datapump+V2+Event+Emitter+Consumers+-+Architecture